# I. Conteneurisation avec Docker
## 1. DÃ©finition dâ€™un conteneur Docker
### Docker est une plateforme(PaaS) ouverte(Open Sources) pour dÃ©velopper, livrer et exÃ©cuter des applications.

Docker permet de **sÃ©parer vos applications de votre infrastructure**, ce qui vous permet de livrer des logiciels plus rapidement.

Avec Docker, vous pouvez **gÃ©rer votre infrastructure de la mÃªme maniÃ¨re que vous gÃ©rez vos applications**.

(*selon le site officiel de docker [https://docs.docker.com/get-started/docker-overview/*](https://docs.docker.com/get-started/docker-overview/*))

La grande innovation de Docker est de permettre de â€œpackagerâ€ une application ou un ensemble de services dans des conteneurs. Un conteneur Docker est une instance dâ€™une application qui contient toutes les bibliothÃ¨ques et composants nÃ©cessaires au fonctionnement dâ€™une application. Dâ€™un point de vue pratique, un conteneur est une sorte de machine virtuelle limitÃ©e qui fonctionne indÃ©pendamment du systÃ¨me dâ€™exploitation dans lequel une application ou un service spÃ©cifique est exÃ©cutÃ©.

Un conteneur Docker est gÃ©nÃ©rÃ© Ã  partir dâ€™une image qui est le rÃ©sultat de lâ€™application ou du service packagÃ©. Il peut contenir un systÃ¨me dâ€™exploitation complet ou des applications prÃ©-installÃ©es. Câ€™est-Ã -dire quâ€™Ã  partir dâ€™une image, le conteneur se met Ã  fonctionner.

_([https://www.hostinger.com/fr/tutoriels/installer-docker-sur-ubuntu](https://www.hostinger.com/fr/tutoriels/installer-docker-sur-ubuntu))_

## ğŸ§± Architecture de Docker â€“ Vue dâ€™ensemble
### âš™ï¸ 1. **Docker Engine** (le cÅ“ur de Docker)

Câ€™est le moteur principal de Docker. Il se compose de deux parties :

- **Docker Daemon (`dockerd`)** : Câ€™est un service qui tourne en arriÃ¨re-plan sur la machine. Il exÃ©cute les commandes Docker, gÃ¨re les **conteneurs, images, rÃ©seaux, volumes**, etc.
    
- **Docker Client (`docker`)** : Câ€™est ce que tu utilises dans le terminal pour parler au daemon. Quand tu tapes une commande comme `docker run`, câ€™est le client qui lâ€™envoie au daemon.
    

---

### ğŸ–¼ï¸ 2. **Docker Images**

- Une **image Docker** est comme un **modÃ¨le** ou une **photo figÃ©e** dâ€™un environnement dâ€™application (ex : une appli Node.js avec ses dÃ©pendances).
    
- Elles sont **crÃ©Ã©es Ã  partir de fichiers `Dockerfile`**, qui contiennent des instructions (comme "installe Node", "copie les fichiers", etc.).
    
- Les images sont **en lecture seule**. Pour les utiliser, on les transforme en conteneurs.
    

---

### ğŸ“¦ 3. **Docker Containers**

- Un **conteneur** est une **instance vivante** dâ€™une image.
    
- Câ€™est lÃ  que lâ€™application tourne, de maniÃ¨re **isolÃ©e**.
    
- Tu peux **crÃ©er, dÃ©marrer, arrÃªter, dÃ©placer ou supprimer** des conteneurs facilement avec Docker.
    

---

### ğŸ—‚ï¸ 4. **Docker Registry**

- Un **registry** est un endroit pour **stocker et partager des images**.
    
- Le plus connu est **Docker Hub** (public), mais tu peux aussi avoir ton propre **registry privÃ©** pour tes images internes Ã  ton entreprise.
    

---

### ğŸ§© 5. **Docker Compose**

- **Docker Compose** est un outil qui te permet de **gÃ©rer plusieurs conteneurs** ensemble.
    
- Tu dÃ©cris toute ton appli (les services, rÃ©seaux, volumes...) dans un **fichier YAML (`docker-compose.yml`)**.
    
- TrÃ¨s utile pour les applis complexes avec plusieurs composants (ex : une app web + une base de donnÃ©es + un cache).
    

---

### ğŸ’¾ 6. **Docker Volumes**

- Les **volumes** servent Ã  **garder les donnÃ©es mÃªme quand un conteneur est supprimÃ©**.
    
- Par exemple : si ta base de donnÃ©es est dans un conteneur, tu ne veux pas perdre les donnÃ©es Ã  chaque redÃ©marrage â†’ tu utilises un volume.
    

---

### ğŸŒ 7. **Docker Networking**

- Docker crÃ©e des **rÃ©seaux virtuels** pour que les conteneurs puissent **communiquer entre eux** ou avec lâ€™extÃ©rieur.
    
- Tu peux avoir des **rÃ©seaux isolÃ©s**, des **rÃ¨gles de communication**, etc.
    
- Tu peux mÃªme connecter plusieurs conteneurs ensemble via Compose ou en ligne de commande.
-Architecture de docker ![[Architecture Docker 1.png]]

*(https://medium.com/@ravipatel.it/understanding-docker-architecture-a-comprehensive-guide-5ce9129df1a4)*
## 2. DiffÃ©rences entre conteneur et machine virtuelle

- **Conteneur :**
    - LÃ©ger et rapide
    - Ne contient que lâ€™application et ses dÃ©pendances
    - Partage le systÃ¨me dâ€™exploitation de la machine hÃ´te
    - DÃ©marre en quelques secondes
- **Machine virtuelle (VM) :**
    - Plus lourde
    - Contient un systÃ¨me dâ€™exploitation complet en plus de lâ€™application
    - NÃ©cessite plus de ressources (RAM, CPU)
    - DÃ©marre en plusieurs minutes

|Aspect|Conteneur Docker|Machine Virtuelle (VM)|
|---|---|---|
|**Isolation**|Partage le noyau de lâ€™OS hÃ´te, mais est isolÃ©|ComplÃ¨tement isolÃ©e, y compris OS invitÃ©|
|**Poids**|TrÃ¨s lÃ©ger|Lourd (OS complet dans chaque VM)|
|**Temps de dÃ©marrage**|Quelques secondes|Plusieurs dizaines de secondes Ã  minutes|
|**Performance**|Plus rapide et proche des performances natives|Moins performant Ã  cause de lâ€™hyperviseur|
|**Consommation de ressources**|Moins de RAM et CPU requis|Plus gourmand en ressources|
|**PortabilitÃ©**|TrÃ¨s portable (fonctionne partout oÃ¹ Docker est installÃ©)|PortabilitÃ© plus limitÃ©e|
|**Cas dâ€™usage typique**|DÃ©veloppement, microservices, CI/CD|Virtualisation dâ€™environnements complets|

_(selon ChatGPT)_

## 3. Principe dâ€™un Dockerfile

### Quâ€™est-ce quâ€™un Dockerfile ?

Un **Dockerfile** est un fichier texte qui contient les **instructions nÃ©cessaires Ã  la crÃ©ation dâ€™une image Docker personnalisÃ©e**. Chaque ligne du Dockerfile reprÃ©sente une **Ã©tape de construction** que Docker exÃ©cutera pour gÃ©nÃ©rer l'image.

### ğŸ”§ Exemple simple :

```yaml
# Utiliser une image de base
FROM node:18

# CrÃ©er un dossier de travail
WORKDIR /app

# Copier les fichiers du projet
COPY . .

# Installer les dÃ©pendances
RUN npm install

# DÃ©marrer lâ€™application
CMD ["npm", "start"]
```

|Instruction|RÃ´le|
|---|---|
|`FROM`|SpÃ©cifie lâ€™image de base (ex. `ubuntu`, `node`, etc.)|
|`WORKDIR`|DÃ©finit le dossier de travail Ã  lâ€™intÃ©rieur du conteneur|
|`COPY`|Copie des fichiers du systÃ¨me hÃ´te vers lâ€™image|
|`RUN`|ExÃ©cute une commande (ex : installation de paquets)|
|`CMD`|DÃ©finit la commande Ã  exÃ©cuter quand le conteneur dÃ©marre|
|`EXPOSE`|Indique le port sur lequel lâ€™application tourne (facultatif)|

### 1. ğŸ§¾ **Dockerfile â†’ Image**

Le **Dockerfile** est un **fichier texte** contenant les **instructions** pour construire une **image Docker**.

```
docker build -t mon-image .
```

### 2. ğŸ“¦ **Image â†’ Conteneur**

Une **image Docker** est un **modÃ¨le statique** (un peu comme un template ou une photo figÃ©e) de ce que sera un environnement dâ€™exÃ©cution.

### 3. ğŸ§± **Conteneur â†’ Noeud**

Un **nÅ“ud (ou node)** est une **machine (physique ou virtuelle)** qui **exÃ©cute Docker**. Câ€™est lâ€™environnement qui hÃ©berge et fait tourner les conteneurs.

- Un **conteneur sâ€™exÃ©cute toujours sur un nÅ“ud Docker**.
- Si tu utilises **Kubernetes**, un nÅ“ud est une **machine du cluster** capable dâ€™hÃ©berger plusieurs conteneurs orchestrÃ©s.

```
Dockerfile âœ Image âœ Conteneur âœ Noeud
    |          |         |          |
 Recette   ModÃ¨le    Instance   Machine
```

En resume

A partir du **Dockefile** on contruit un **Image** et de ce dernier on construit **Conteneur** celui ci tourne dans un **Noeud**

_(ChatGPT)_

# Une rÃ©volution pour le cloud ?

Venons-en au fait : est-ce que Docker va rÃ©volutionner le cloud ? Ouiâ€¦ et non ! En fait, tout dÃ©pend de la faÃ§on dont il Ã©voluera. En thÃ©orie, cela pourrait Ãªtre le cas puisquâ€™il permet deux choses cruciales.

Tout dâ€™abord, la rÃ©duction des ressources nÃ©cessaires au dÃ©ploiement dâ€™un cloud. GrÃ¢ce Ã  lâ€™utilisation des conteneurs pouvant faire tourner des applications sans systÃ¨me dâ€™exploitation embarquÃ© et Ã  lâ€™absence dâ€™hyperviseur, on peut envisager un cloud tournant sur des infrastructures serveurs moins puissantes, plus petites, et donc moins coÃ»teuses.

De plus, Ã©tant donnÃ© que Docker a Ã©tÃ© conÃ§u pour faciliter la portabilitÃ© des conteneurs, on peut envisager la migration entre diffÃ©rentes infrastructures (ex : de serveurs Windows Ã  des serveurs Linux), voire mÃªme la redondance en temps rÃ©el entre ces infrastructures.

Mais nous nâ€™en sommes, pour le moment, quâ€™Ã  la thÃ©orie. Docker est une application qui, dans sa forme actuelle, est surtout destinÃ©e aux dÃ©veloppeurs. Ainsi, elle sâ€™avÃ¨re idÃ©ale pour tester, en quelques secondes via un serveur de dÃ©veloppement peu performant, la qualitÃ© dâ€™un dÃ©veloppement sur plusieurs systÃ¨mes. Au-delÃ , Docker nâ€™est pas encore assez performant et ne fait pas le poids face aux systÃ¨mes de virtualisation qui ont plusieurs annÃ©es dâ€™expÃ©riences. De plus, actuellement, Docker est clairement utilisÃ© dans des machines virtuelles classiques pour permettre Ã  plus dâ€™applications de tourner sans consommer plus de ressources. Il est donc perÃ§u comme une brique complÃ©mentaire de la virtualisation classique, et non comme un concurrent.

Ainsi, et bien quâ€™il nâ€™en soit quâ€™Ã  ses dÃ©buts, il est important de suivre le dÃ©veloppement de ce petit poucet qui pourrait bien, prochainement, devenir aussi gros que lâ€™ogre.

_Sources: ([https://www.diatem.net/cloud-docker/](https://www.diatem.net/cloud-docker/))_

# Docker, seule solution de conteneurs ?

Pour finir, il est important de signaler que Docker nâ€™est pas la seule solution Ã  envisager les conteneurs pour remplacer, ou complÃ©ter, la virtualisation par hyperviseur.

Et mÃªme plus, Docker fait aujourdâ€™hui face Ã  un concurrent de taille qui critique sÃ¨chement son modÃ¨le, aprÃ¨s lâ€™avoir pourtant officiellement soutenu. Ce concurrent, câ€™est CoreOS, la sociÃ©tÃ© Ã©ditrice de la distribution Linux du mÃªme nom. CoreOS a dÃ©cidÃ©, suite Ã  des divergences dâ€™opinions sur ce que devait Ãªtre les conteneurs et leur faÃ§on de fonctionner, de dÃ©velopper son propre standard et son environnement.

Ainsi, CoreOS a crÃ©Ã© App Container, un standard qui sâ€™appuie sur Rocket, la technologie permettant la construction et la gestion des conteneurs.

Il nâ€™est pas question ici de dÃ©partager les deux solutions, ni mÃªme de rÃ©sumer le dÃ©bat qui les oppose. Mais il est important de souligner que la solution de CoreOS a reÃ§u, officiellement, des soutiens de poids en mai 2015. Ces soutiens ce sont des employÃ©s de Google, de Red Hat (distribution Linux) et de Twitter. Mais, en annonÃ§ant un soutien officiel, ces employÃ©s indique officieusement que leur employeur soutient aussi App Container. Et ce nâ€™est pas tout puisque VMware et Apcera, deux gros acteurs du cloud, ont aussi apportÃ© leur soutien.

Autant dire que Docker, mÃªme sâ€™il fait de plus en plus parler de lui, nâ€™est pas encore sÃ»r de sâ€™imposer sur le marchÃ©. Il ne faut donc pas nÃ©gliger App Container, ainsi que dâ€™autres solutions qui peuvent Ã©merger, et continuer Ã  suivre lâ€™Ã©volution des technologies de conteneurs qui nâ€™en sont, pour le moment, quâ€™Ã  leurs dÃ©buts.

## 4. DÃ©crire une application avec Docker

Pour dÃ©crire une application avec Docker, vous devez crÃ©er un fichier appelÃ© Dockerfile qui contient une sÃ©rie d'instructions permettant de dÃ©finir l'environnement dans lequel une application sera exÃ©cutÃ©e.Ces instructions peuvent inclure l'installation de logiciels, la copie de fichiers, la dÃ©finition de variables d'environnement, etc. Le Dockerfile est essentiel pour automatiser la crÃ©ation d'une image Docker, en spÃ©cifiant les dÃ©pendances, les fichiers Ã  copier, les commandes Ã  exÃ©cuter, etc.Chaque ligne du Dockerfile correspond Ã  une Ã©tape dans le processus de construction de l'image.

Une fois le Dockerfile crÃ©Ã©, vous pouvez utiliser la commande docker build pour construire une image Docker Ã  partir de ce fichier.

Cette image contiendra tout ce dont votre application a besoin pour fonctionner : le code, les bibliothÃ¨ques, les dÃ©pendances et les configurations systÃ¨me.

Une fois l'image construite, vous pouvez utiliser la commande docker run pour crÃ©er et dÃ©marrer un conteneur Ã  partir de cette image.

[*](https://search.brave.com/search?q=Comment+D%C3%A9crire+une+application+avec+Docker&source=desktop&conversation=d1109d60b7fc86bcb78f1f&summary=1)[https://search.brave.com/search?q=Comment+DÃ©crire+une+application+avec+Docker&source=desktop&conversation=d1109d60b7fc86bcb78f1f&summary=1*](https://search.brave.com/search?q=Comment+D%C3%A9crire+une+application+avec+Docker&source=desktop&conversation=d1109d60b7fc86bcb78f1f&summary=1*)

## **1.Â DockerfileÂ (pour une application simple)**

![[Docker.png]]

LeÂ **`Dockerfile`**Â dÃ©crit les Ã©tapes pour construire une image Docker contenant votre application.

### **Exemple pour une application Python :**

```yaml
# Ã‰tape 1 : Utiliser une image de base officielle
FROM python:3.9-slim

# Ã‰tape 2 : DÃ©finir le rÃ©pertoire de travail dans le conteneur
WORKDIR /app

# Ã‰tape 3 : Copier les fichiers nÃ©cessaires
COPY requirements.txt .
COPY app.py .

# Ã‰tape 4 : Installer les dÃ©pendances
RUN pip install --no-cache-dir -r requirements.txt

# Ã‰tape 5 : Exposer le port utilisÃ© par l'application
EXPOSE 5000

# Ã‰tape 6 : Commande Ã  exÃ©cuter au lancement du conteneur
CMD ["python", "app.py"]
```

### **Explications :**

- **`FROM`**Â : L'image de base (Python, Node.js, Java, etc.).
- **`WORKDIR`**Â : Le rÃ©pertoire oÃ¹ les commandes suivantes seront exÃ©cutÃ©es.
- **`COPY`**Â : Copie des fichiers locaux vers l'image.
- **`RUN`**Â : ExÃ©cute une commande pendant la construction (installation de dÃ©pendances).
- **`EXPOSE`**Â : Indique le port Ã  exposer.
- **`CMD`**Â : La commande qui dÃ©marre l'application.

## **2.Â Docker ComposeÂ (pour une application multi-conteneurs)**

Si votre application utilise plusieurs services (ex. : base de donnÃ©es, backend, frontend), utilisezÂ **`docker-compose.yml`**.

### **Exemple avec une API Flask + PostgreSQL :**

```yaml
version: '3.8'

services:
  # Service pour l'application Flask
  web:
    build: .  # Construit l'image Ã  partir du Dockerfile
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=development
    depends_on:
      - db

  # Service pour PostgreSQL
  db:
    image: postgres:13
    environment:
      - POSTGRES_USER=myuser
      - POSTGRES_PASSWORD=mypassword
    volumes:
      - postgres_data:/var/lib/postgresql/data

# Volume pour persister les donnÃ©es de la base
volumes:
  postgres_data:
```

### **Explications :**

- **`services`**Â : DÃ©finit les diffÃ©rents conteneurs.
- **`build`**Â : Construit l'image depuis leÂ **`Dockerfile`**.
- **`ports`**Â : Mappe les ports (host:conteneur).
- **`environment`**Â : DÃ©finit des variables d'environnement.
- **`depends_on`**Â : Indique les dÃ©pendances entre services.
- **`volumes`**Â : Persiste les donnÃ©es (ici pour PostgreSQL).

## **3.Â Commandes Utiles**

### **Construire et lancer avec Docker :**

```bash
docker build -t mon-app .          # Construit l'image
docker run -p 5000:5000 mon-app    # Lance le conteneur
```

### **Lancer avec Docker Compose :**

```bash
docker-compose up -d  # Lance les services en arriÃ¨re-plan
docker-compose down   # ArrÃªte et supprime les conteneurs
```

## 5. Fonctionnement de Docker Compose

### ğŸ”· Quâ€™est-ce que Docker Compose ?

Docker Compose est un outil qui te permet de **dÃ©crire, configurer et exÃ©cuter plusieurs conteneurs Docker** Ã  lâ€™aide dâ€™un **fichier YAML** (`docker-compose.yml`).

> âš™ï¸ Il agit comme un orchestrateur lÃ©ger pour dÃ©marrer tous tes services avec une seule commande.

---

### ğŸ“„ Exemple simple : une app web + base de donnÃ©es

```yaml
version: "3.8"
services:
  web: #Partie pour service WEB
    image: my-web-app
    ports:
      - "8080:80" #port 
    depends_on:
      - db

  db:# Partie pour le Service database
    image: mysql:5.7
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: mydb #nom de la base de donnees
```

 Fonctionnement global de Docker Compose

| Ã‰tape                  | Ce que fait Docker Compose                                        |
| ---------------------- | ----------------------------------------------------------------- |
| `docker-compose.yml`   | DÃ©crit tous les conteneurs, images, ports, volumes, rÃ©seaux, etc. |
| `docker compose up`    | CrÃ©e et dÃ©marre tous les services Ã  partir du fichier YAML        |
| `docker compose down`  | ArrÃªte et supprime tous les conteneurs, rÃ©seaux, etc.             |
| `docker compose build` | Construit les images Docker si tu as un `Dockerfile`              |
| `docker compose ps`    | Affiche les services en cours dâ€™exÃ©cution                         |

## Pourquoi utiliser Kubernetes alors quâ€™on a dÃ©jÃ  Docker Compose ?

Docker Compose est super pour **un dÃ©veloppeur ou une petite Ã©quipe**, mais quand tu passes Ã  **une application Ã  grande Ã©chelle**, tu as besoin de beaucoup plus de contrÃ´le, de rÃ©silience, dâ€™automatisation... Câ€™est lÃ  que **Kubernetes** entre en jeu.

## Docker Compose vs Kubernetes â€“ Comparaison complÃ¨te

| FonctionnalitÃ© / Besoin                | **Docker Compose** | **Kubernetes**                          |
| -------------------------------------- | ------------------ | --------------------------------------- |
| DÃ©finir plusieurs conteneurs           | âœ… Oui              | âœ… Oui                                   |
| Lancer un projet multi-services        | âœ… Simple et rapide | âœ… Plus complexe Ã  configurer            |
| PortabilitÃ© environnement dev          | âœ… TrÃ¨s bien adaptÃ© | âš ï¸ Moins adaptÃ© (plus lourd)            |
| ScalabilitÃ© automatique (auto-scaling) | âŒ Non              | âœ… Oui                                   |
| RedÃ©marrage automatique (self-healing) | âŒ Non              | âœ… Oui                                   |
| Gestion d'Ã©tat du cluster              | âŒ Non              | âœ… Kubernetes gÃ¨re les nÅ“uds, pods, etc. |
| DÃ©ploiement dans le cloud              | âš ï¸ Peu adaptÃ©      | âœ… IntÃ©gration native (AWS, GCP, Azure)  |
| Rolling updates, rollback              | âŒ Non              | âœ… Oui                                   |
| Load balancing intÃ©grÃ©                 | âŒ (manuel)         | âœ… Oui (service, ingressâ€¦)               |
| Gestion des secrets                    | âŒ Basique          | âœ… AvancÃ©e (Secrets, ConfigMaps)         |

## 6. Orchestration de plusieurs conteneurs

## **Orchestration de plusieurs conteneurs** : câ€™est quoi ?

Câ€™est le **processus dâ€™automatisation** de la gestion de plusieurs conteneurs, pour quâ€™ils fonctionnent ensemble **de maniÃ¨re fluide, efficace et stable**, surtout quand Ã§a devient gros ou complexe.

Imagine une application composÃ©e de :

- un serveur web (Nginx),
- une API Node.js,
- une base de donnÃ©es PostgreSQL,
- un service de cache Redis.

Tu pourrais les lancer Ã  la main avec `docker run`, un par unâ€¦ mais ce serait vite **ingÃ©rable**.

>  Lâ€™orchestration sâ€™en occupe pour toi

# II. Orchestration avec Kubernetes

##  **ARCHITECTURE ET COMPOSANTS DE KUBERNETES**

*image venant de* :https://beopenit.com/qu-est-ce-que-kubernetes/
![[Screenshot from 2025-04-21 16-05-12.png]]
### â€”  PLAN DE CONTRÃ”LE (CONTROL PLANE)

Le **plan de contrÃ´le**, ou **nÅ“ud maÃ®tre**(Kubernetes Master)**, est lâ€™unitÃ© centrale de gestion dâ€™un cluster Kubernetes. Il supervise lâ€™ensemble des opÃ©rations du cluster et coordonne son fonctionnement. Il prend des dÃ©cisions de haut niveau sur le dÃ©ploiement des applications et veille Ã  ce que lâ€™Ã©tat rÃ©el du cluster corresponde Ã  lâ€™Ã©tat souhaitÃ©.

- **API Server (Serveur API)** :  
    Câ€™est le **point dâ€™entrÃ©e** pour interagir avec le cluster Kubernetes. Il expose lâ€™API Kubernetes, que les utilisateurs, administrateurs et autres composants peuvent utiliser pour communiquer avec le cluster.
    
- **etcd** :  
    Câ€™est une base de donnÃ©es **clÃ©-valeur distribuÃ©e**. Elle sert de **stockage central** pour toutes les donnÃ©es du cluster (Pods, Services, configurations de rÃ©plication, etc.).
    
- **Controller Manager (Gestionnaire de contrÃ´leurs)** :  
    Il surveille lâ€™Ã©tat des objets du cluster et prend des **actions correctives** pour maintenir lâ€™Ã©tat dÃ©sirÃ©. Il comprend plusieurs contrÃ´leurs intÃ©grÃ©s comme le **Replication Controller**, le **Deployment Controller** ou le **StatefulSet Controller**.
    
- **Scheduler (Planificateur)** :  
    Il choisit sur quel nÅ“ud **exÃ©cuter les Pods**, en fonction de la disponibilitÃ© des ressources, des contraintes et des objectifs dâ€™optimisation.
    

 Ensemble, ces composants forment le **cerveau** du cluster.

---

### â€”  NÅ’UDS TRAVAILLEURS (WORKER NODES)

Les **nÅ“uds de travail**, aussi appelÃ©s **machines de travail**, exÃ©cutent les conteneurs et les charges de travail applicatives.

- **Kubelet** :  
    Câ€™est un **agent** qui sâ€™exÃ©cute sur chaque nÅ“ud. Il communique avec le plan de contrÃ´le et sâ€™assure que les conteneurs sont bien lancÃ©s et fonctionnels.
    
- **Kube Proxy** :  
    Il sâ€™occupe du **routage rÃ©seau** et de lâ€™**Ã©quilibrage de charge**, pour permettre la communication entre les applications.
    
- **Container Runtime (Moteur de conteneurisation)** :  
    Câ€™est le logiciel chargÃ© dâ€™**exÃ©cuter les conteneurs** sur chaque nÅ“ud.
    
- **CSI (Container Storage Interface)** :  
    Interface standardisÃ©e permettant aux nÅ“uds dâ€™accÃ©der Ã  des solutions de stockage **persistant**.
    

---

### â€”  PODS

LesÂ _Pods_Â sont les plus petites unitÃ©s informatiques dÃ©ployables qui peuvent Ãªtre crÃ©Ã©es et gÃ©rÃ©es dans Kubernetes.
*selon le site officielles de kubernetes : (https://kubernetes.io/fr/docs/concepts/workloads/pods/pod/)*

Les **Pods** sont les unitÃ©s fondamentales de Kubernetes. Ils regroupent un ou plusieurs conteneurs qui partagent le mÃªme rÃ©seau et les mÃªmes volumes de stockage.

En terme de conceptsÂ [Docker](https://www.docker.com/), un pod est modÃ©lisÃ© par un groupe de conteneurs Docker ayant des namespaces et desÂ [volumes](https://kubernetes.io/fr/docs/concepts/storage/volumes/)Â partagÃ©s.

Un Pods est exposÃ© en tant que primitive afin de faciliter :

- la connexion du scheduler et du contrÃ´leur
- la possibilitÃ© d'opÃ©rations au niveau du pod sans besoin de passer par des APIs au niveau du contrÃ´leur
- le dÃ©couplage du cycle de fin d'un pod de celui d'un contrÃ´leur, comme pour l'amorÃ§age (bootstrapping)
- le dÃ©couplage des contrÃ´leurs et des services â€” le contrÃ´leur d'endpoints examine uniquement des pods
- la composition claire des fonctionnalitÃ©s niveau Kubelet et des fonctionnalitÃ©s niveau cluster â€” concrÃ¨tement, Kubelet est le "contrÃ´leur de pods"
- les applications hautement disponibles, qui attendront que les pods soient remplacÃ©s avant leur arrÃªt et au moins avant leur suppression, comme dans les cas d'Ã©viction programmÃ©e ou de prÃ©-chargement d'image.




- **Co-localisation des conteneurs** :  
    Les conteneurs dâ€™un Pod peuvent **communiquer via localhost** et partagent IP et ports.
    
- **Stockage partagÃ©** :  
    Les volumes montÃ©s dans un Pod peuvent Ãªtre utilisÃ©s par tous les conteneurs de celui-ci.
    
- **UnitÃ© de dÃ©ploiement** :  
    Kubernetes dÃ©ploie et gÃ¨re les **Pods**, pas les conteneurs individuellement.
    
- **Init Containers** :  
    Ce sont des conteneurs spÃ©ciaux qui sâ€™exÃ©cutent **avant** les conteneurs principaux.
    

---

### â€”  CONTRÃ”LEURS

Les **contrÃ´leurs** veillent Ã  ce que lâ€™Ã©tat rÃ©el des ressources corresponde Ã  lâ€™Ã©tat dÃ©sirÃ©. Ils automatisent la **scalabilitÃ©**, la **guÃ©rison automatique** et la **gestion des applications**.

- **Replication Controller** :  
    Garantit quâ€™un **nombre exact de Pods** est toujours en fonctionnement.
    
- **Deployment** :  
    GÃ¨re les **mises Ã  jour progressives** (rolling updates) des applications et permet les **rollbacks**.
    
- **StatefulSet** :  
    GÃ¨re les applications **avec Ã©tat** (base de donnÃ©es, etc.) en leur attribuant une **identitÃ© stable**.
    
- **DaemonSet** :  
    Fait en sorte quâ€™un **Pod spÃ©cifique tourne sur chaque nÅ“ud** (utile pour les logs, la surveillance...).
    
- **Horizontal Pod Autoscaler (HPA)** :  
    Ajuste automatiquement le nombre de Pods en fonction de la **charge CPU** ou dâ€™autres mÃ©triques.
    
- **Vertical Pod Autoscaler (VPA)** :  
    Modifie les **ressources allouÃ©es** aux Pods selon leur consommation rÃ©elle.
    

---

### â€”  SERVICES

Les **Services** facilitent la communication entre Pods et assurent un **Ã©quilibrage de charge**.

1. **Types de services** :
    
    - **ClusterIP** : IP interne accessible uniquement dans le cluster.
        
    - **NodePort** : Expose le service sur un port fixe de chaque nÅ“ud.
        
    - **LoadBalancer** : CrÃ©e un load balancer externe pour exposer le service.
        
    - **ExternalName** : Redirige vers un **nom DNS externe**.
        
2. **SÃ©lecteurs et Ã©tiquettes (labels)** :  
    Les Services ciblent les Pods via des **labels**.
    
3. **Load Balancing** :  
    Les requÃªtes envoyÃ©es Ã  un Service sont **rÃ©parties entre les Pods** associÃ©s.
    
4. **Services Headless** :  
    Ne fournit **pas dâ€™IP stable** mais permet un **accÃ¨s direct aux Pods**.
    

---

### â€”  VOLUMES

Les **volumes** offrent un **stockage persistant** aux conteneurs.

1. **Types de volumes** :
    
    - **EmptyDir** : Temporaire, supprimÃ© avec le Pod.
        
    - **HostPath** : Monte un fichier/dossier du nÅ“ud (non recommandÃ© en production).
        
    - **PersistentVolumeClaim (PVC)** : RequÃªte pour un volume persistant, dynamique.
        
    - **ConfigMap / Secret** : Injecte des fichiers de config ou des secrets.
        
    - **NFS** : Utilise un stockage rÃ©seau partagÃ©.
        
    - **CSI** : Permet lâ€™intÃ©gration de solutions de stockage tierces.
        

---

### â€” ğŸ” CONFIGMAPS ET SECRETS

- **ConfigMaps** :  
    Stockent des **donnÃ©es de configuration non sensibles** sous forme de paires clÃ©-valeur.
    
- **Secrets** :  
    Stockent des **informations sensibles** comme mots de passe, clÃ©s API, certificatsâ€¦ en toute sÃ©curitÃ©.
    

---

### â€” ğŸ§± NAMESPACES

Les **namespaces** permettent dâ€™organiser et dâ€™isoler les ressources dans un cluster.

1. **Objectifs** :
    
    - **Isolation** des ressources par projet, Ã©quipe ou environnement.
        
    - **Gestion des accÃ¨s** (RBAC).
        
    - **Quota de ressources**.
        
2. **Namespace par dÃ©faut** :  
    Si aucun namespace nâ€™est prÃ©cisÃ©, les ressources sont crÃ©Ã©es dans le **namespace `default`**.
    
3. **PortÃ©e** :  
    Certaines ressources (Nodes, Volumes) sont **globales**, d'autres sont **propres Ã  un namespace** (Pods, Servicesâ€¦).
    

---

### â€” ğŸŒ INGRESS

Lâ€™**Ingress** permet de **gÃ©rer lâ€™accÃ¨s externe** aux services du cluster, souvent via HTTP/HTTPS.

1. **Objectif** :  
    Agit comme **point dâ€™entrÃ©e** du cluster pour exposer les applications.
    
2. **Fonctionnement** :  
    Lâ€™Ingress dÃ©finit des **rÃ¨gles de routage** basÃ©es sur les noms de domaine ou chemins.
    
3. **Ingress Controller** :  
    Câ€™est un composant (comme NGINX ou Traefik) qui **applique les rÃ¨gles** dÃ©finies dans les Ingress.
    
Source :(https://medium.com/@himanshusangshetty/kubernetes-architecture-and-components-explained-e489e98db15d)

![[Kubernetes-Architecture.webp]]

*source :(https://www.opsramp.com/guides/why-kubernetes/kubernetes-architecture/)*
## 1. Concepts de base : Pod, Service, Deployment, Cluster

### [Kubernetes (K8s)](https://kubernetes.io/fr/docs/concepts/overview/)Â 


***est un systÃ¨me open-source permettant d'automatiser le dÃ©ploiement, la mise Ã  l'Ã©chelle et la gestion des applications conteneurisÃ©es***
Les conteneurs qui composent une application sont regroupÃ©s dans des unitÃ©s logiques pour en faciliter la gestion et la dÃ©couverte. Kubernetes sâ€™appuie surÂ [15 annÃ©es dâ€™expÃ©rience dans la gestion de charges de travail de production (workloads) chez Google](https://queue.acm.org/detail.cfm?id=2898444), associÃ© aux meilleures idÃ©es et pratiques de la communautÃ©.

#### Quel que soit le nombre[](https://kubernetes.io/fr/#quel-que-soit-le-nombre)

ConÃ§u selon les mÃªmes principes qui permettent Ã  Google de gÃ©rer des milliards de conteneurs par semaine, Kubernetes peut Ã©voluer sans augmenter votre Ã©quipe d'opÃ©rations.

#### Quelle que soit la complexitÃ©Â [](https://kubernetes.io/fr/#quelle-que-soit-la-complexit%C3%A9)

Qu'il s'agisse de tester localement ou d'une implÃ©mentation globale, Kubernetes est suffisamment flexible pour fournir vos applications de maniÃ¨re cohÃ©rente et simple, quelle que soit la complexitÃ© de vos besoins.

#### Quel que soit l'endroit[](https://kubernetes.io/fr/#quel-que-soit-l-endroit)

Kubernetes est une solution open-source qui vous permet de tirer parti de vos infrastructures qu'elles soient sur site (on-premises), hybride ou en Cloud publique. Vous pourrez ainsi rÃ©partir sans effort vos workloads lÃ  oÃ¹ vous le souhaitez.

Source Site Officielles :(https://kubernetes.io/fr/)
# **Orchestration avec Kubernetes : Concepts de base**

---

## ğŸ”¹ 1. **Pod** â€“ _Lâ€™unitÃ© de base dans Kubernetes_

- Un **Pod** est la plus petite unitÃ© dÃ©ployable dans Kubernetes.
- Il reprÃ©sente **un ou plusieurs conteneurs** qui partagent :
    - Le **rÃ©seau** (mÃªme IP, mÃªme port space)
    - Le **stockage** (volumes partagÃ©s)
    - Et sont gÃ©rÃ©s ensemble.
- Les conteneurs dâ€™un mÃªme Pod sont **fortement liÃ©s** (ex : un conteneur dâ€™app + un conteneur de monitoring).

> ğŸ¯ But : Grouper des conteneurs qui doivent fonctionner ensemble dans un mÃªme environnement isolÃ©.

---

## ğŸ”¹ 2. **Service** â€“ _La couche rÃ©seau et de communication_

- Un **Service** est un **abstrait rÃ©seau** qui **expose un ou plusieurs Pods** via une adresse IP stable et un nom DNS.
- Il permet :
    - La **dÃ©couverte de services** dans le cluster.
    - Le **load balancing** automatique entre Pods similaires.
    - Lâ€™**exposition vers lâ€™extÃ©rieur** (si besoin).

> ğŸ¯ But : Garantir que les applications puissent se parler mÃªme si les Pods changent ou redÃ©marrent.

### Types de Services :

| Type             | Description                                     |
| ---------------- | ----------------------------------------------- |
| **ClusterIP**    | Accessible uniquement dans le cluster           |
| **NodePort**     | Ouvert sur un port des nÅ“uds pour accÃ¨s externe |
| **LoadBalancer** | Utilise un load balancer cloud (AWS, GCPâ€¦)      |

---

## ğŸ”¹ 3. **Deployment** â€“ _La stratÃ©gie de dÃ©ploiement et de mise Ã  jour_

- Un **Deployment** dÃ©crit **comment dÃ©ployer, gÃ©rer et mettre Ã  jour** un ensemble de Pods.
- Il spÃ©cifie :
    - Le **nombre de rÃ©plicas** (copies du Pod).
    - Lâ€™**image Docker** Ã  utiliser.
    - Les **mises Ã  jour sans interruption** (rolling updates).
    - Le **rollback automatique** en cas dâ€™Ã©chec.

> ğŸ¯ But : Assurer un dÃ©ploiement fiable, scalable et maintenable de lâ€™application.

En resume
```
Cluster
â”œâ”€â”€ Nodes (machines)
â”‚   â””â”€â”€ Pods (exÃ©cutent les conteneurs)
â”‚       â””â”€â”€ Containers (ton app)
â”‚
â”œâ”€â”€ Deployment (gÃ¨re combien de Pods doivent exister)
â”‚
â”œâ”€â”€ Service (expose les Pods via le rÃ©seau)
```
---

## ğŸ”¹ 4. **Cluster** â€“ _Lâ€™ensemble de lâ€™environnement Kubernetes_

- Un **Cluster Kubernetes** est un ensemble de **machines (nÅ“uds)** qui travaillent ensemble :
    - Le **Control Plane** (ou Master) gÃ¨re la logique de lâ€™orchestration.
    - Les **Worker Nodes** exÃ©cutent les Pods et les conteneurs.
- Le cluster est lâ€™**environnement dans lequel tout tourne**.

> ğŸ¯ But : Fournir une plateforme stable, automatisÃ©e et rÃ©siliente pour exÃ©cuter des applications conteneurisÃ©es.

![[Pasted image 20250423125658.png]]
## 2. Quâ€™est-ce que Minikube ?

**Minikube** est un outil qui permet de crÃ©er et de gÃ©rer un cluster Kubernetes local Ã  nÅ“ud unique sur votre ordinateur personnel. Il est principalement utilisÃ© pour l'apprentissage, le dÃ©veloppement et les tests de configurations Kubernetes sans nÃ©cessiter une infrastructure complexe.

[*](https://webpick.info/minikube-mise-en-place-dun-cluster-kubernetes-a-noeud-unique/?utm_source=chatgpt.com)[https://webpick.info/minikube-mise-en-place-dun-cluster-kubernetes-a-noeud-unique/?utm_source=chatgpt.com*](https://webpick.info/minikube-mise-en-place-dun-cluster-kubernetes-a-noeud-unique/?utm_source=chatgpt.com*)

### ğŸ§© FonctionnalitÃ©s principales de Minikube

- **Cluster local Ã  nÅ“ud unique** : Minikube exÃ©cute un cluster Kubernetes dans une machine virtuelle ou un conteneur sur votre machine locale.
- **Support multiplateforme** : Compatible avec Windows, macOS et Linux.
- **FacilitÃ© d'utilisation** : Installation simple et rapide, idÃ©ale pour les dÃ©butants souhaitant se familiariser avec Kubernetes.
- **IntÃ©gration avec kubectl** : Permet d'utiliser les commandes Kubernetes standard pour gÃ©rer le cluster.
- **FonctionnalitÃ©s Kubernetes complÃ¨tes** : Prise en charge de DNS, NodePorts, ConfigMaps, Secrets, Ingress, et plus encore.

*source :[https://kubernetes.io/fr/docs/setup/learning-environment/minikube/*](https://kubernetes.io/fr/docs/setup/learning-environment/minikube/*)

*source : [https://minikube.sigs.k8s.io/?utm_source=chatgpt.com*](https://minikube.sigs.k8s.io/?utm_source=chatgpt.com*)

### âš™ï¸ PrÃ©requis pour l'installation

- **SystÃ¨me d'exploitation** : Windows, macOS ou Linux.
- **Processeur** : 2 cÅ“urs ou plus.
- **MÃ©moire** : 2 Go de RAM minimum.
- **Espace disque** : 20 Go d'espace libre.
- **Connexion Internet** : Requise pour tÃ©lÃ©charger les images nÃ©cessaires.
- **Gestionnaire de machines virtuelles ou de conteneurs** : Docker, VirtualBox, Hyper-V, KVM, etc.

*Sources : [https://minikube.sigs.k8s.io/docs/start/?utm_source=chatgpt.com*](https://minikube.sigs.k8s.io/docs/start/?utm_source=chatgpt.com*)

## 3. Simuler un cluster Kubernetes avec Minikube

#### ğŸ”§ **1. PrÃ©requis**


Avant dâ€™installer Minikube, assure-toi dâ€™avoir :

- **Une machine avec au moins 2 CPU, 2 Go RAM**
    
- **Un hyperviseur** : VirtualBox, Docker, Hyper-V, etc.
    
- **kubectl** : l'outil en ligne de commande pour Kubernetes

â¤ Installer `kubectl` :
```
sudo apt update
sudo apt install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubectl

```

#### ğŸš€ **2. Installer Minikube**


```
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube
```


#### â–¶ï¸ **3. DÃ©marrer un cluster Kubernetes local**

```
minikube start
```
Par dÃ©faut, Minikube utilise **Docker** comme moteur. Si tu veux utiliser un autre hyperviseur :
```
minikube start --driver=virtualbox
```

#### ğŸ§ª **4. Tester que tout fonctionne**
```
kubectl get nodes
```

#### ğŸ§° **5. DÃ©ployer une application de test**

```
kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.4
kubectl expose deployment hello-minikube --type=NodePort --port=8080
minikube service hello-minikube
```

#### ğŸ“Š **6. AccÃ©der au tableau de bord Kubernetes**
```
minikube dashboard
```



# III. Authentification et sÃ©curitÃ©

## 1. RÃ´le de Keycloak : gestion des identitÃ©s.

### â¤ Quâ€™est-ce que Keycloak ?

**Keycloak**, dÃ©veloppÃ© par Red Hat, a pour objectif principal est dâ€™assurer la sÃ©curitÃ© et la facilitÃ© dâ€™utilisation des applications en fournissant des fonctionnalitÃ©s robustes dâ€™authentification et dâ€™autorisation.

*selon le site(https://medium.com/@n.benamor97/comprendre-les-principes-fondamentaux-de-keycloak-50f66267d446)*

**Keycloak** est une solution **open source** de gestion des identitÃ©s (IAM - Identity and Access Management). 

Il gÃ¨re :
- Lâ€™authentification des utilisateurs (login/password, SSOâ€¦)
- Lâ€™autorisation dâ€™accÃ¨s aux applications
- La fÃ©dÃ©ration avec dâ€™autres providers (LDAP, Active Directory, Google, etc.)
- Lâ€™Ã©mission de **tokens OAuth2 / OpenID Connect**

### â¤ RÃ´les principaux :

- **SSO (Single Sign-On)** : un seul login pour accÃ©der Ã  plusieurs services.
- **FÃ©dÃ©ration d'identitÃ©** : centralisation des identitÃ©s provenant de plusieurs sources.
- **Gestion fine des rÃ´les et permissions**.
- **IntÃ©gration OAuth2 / OpenID Connect (OIDC)**.
    

### â¤ Pourquoi lâ€™utiliser dans un cloud privÃ© ?

- SÃ©curise l'accÃ¨s aux applications internes (Dashboard, APIâ€¦)
- Permet de dÃ©lÃ©guer lâ€™authentification Ã  un service robuste
- Sâ€™intÃ¨gre bien avec Kubernetes, Docker, Spring Boot, etc.

## 2. MÃ©canisme OAuth2 et JWT

### â¤ OAuth2

**OAuth 2.0**, successeur du protocole OAuth 1.0 a, estÂ **un framework dâ€™autorisation**Â permettant Ã  une application tierce dâ€™accÃ©der Ã  un service web.

**OAuth2** est un **protocole dâ€™autorisation** permettant Ã  une application dâ€™accÃ©der aux ressources dâ€™un utilisateur sans connaÃ®tre son mot de passe.

#### Les rÃ´les principaux :

- **PropriÃ©taire de la ressource(Resource Owner)** : lâ€™utilisateur
- **Client** : lâ€™application qui demande lâ€™accÃ¨s
- **Serveur dâ€™autorisation(Authorization Server)** : Keycloak dans ton cas
- **Serveur de ressource(Resource Server)** : lâ€™API ou le service protÃ©gÃ©


![[Pasted image 20250424094310.png]]
*image de simulation*

### ğŸ” DÃ©cryptons Ã©tape par Ã©tape :
---

### ğŸ‘¤ **1. Le PropriÃ©taire de la ressource (Resource Owner)**
Câ€™est la **personne qui possÃ¨de la photo**. Il est celui qui donne lâ€™autorisation Ã  une application (le client) pour y accÃ©der.

---

### ğŸ“± **2. Le Client (Application tierce)**
Câ€™est par exemple une app mobile ou un site web qui **veut accÃ©der Ã  la photo** du propriÃ©taire, stockÃ©e sur un serveur tiers (ex: Google Photos).

---

### ğŸ–¥ï¸ **3. Les Serveurs**
Ils sont divisÃ©s en deux parties :
- **Serveur dâ€™autorisation** : celui qui gÃ¨re les autorisations (OAuth).
- **Serveur de ressources** : celui qui hÃ©berge la photo ou la ressource demandÃ©e.

---
#### Flows courants :

- **Authorization Code Flow** : recommandÃ© pour les apps web
- **Client Credentials Flow** : utilisÃ© pour la communication entre services
- **Password Grant** (dÃ©conseillÃ© sauf cas trÃ¨s spÃ©cifiques)
    

### â¤ JWT (JSON Web Token)

Les **JWT** sont des **tokens** (jetons) gÃ©nÃ©rÃ©s par Keycloak (ou tout serveur OAuth2) pour prouver lâ€™identitÃ© de lâ€™utilisateur.

#### Composition dâ€™un JWT :

1. **Header** : algorithme de signature
2. **Payload** : les claims (identitÃ©, rÃ´les, durÃ©eâ€¦)
3. **Signature** : permet de vÃ©rifier que le token nâ€™a pas Ã©tÃ© modifiÃ©.
Exemple:
```
{
  "sub": "user123",
  "name": "Alice",
  "roles": ["admin"],
  "exp": 1682542800
}
```
## 3. Fonctionnement des tokens dâ€™authentification.

### â¤ Cycle typique :

1. Lâ€™utilisateur se connecte via une page gÃ©rÃ©e par Keycloak.
2. Keycloak authentifie lâ€™utilisateur et gÃ©nÃ¨re :
    
    - un **access token (JWT)** : pour accÃ©der aux API
    - un **refresh token** : pour renouveler le token sans reconnecter
3. Le token est envoyÃ© au client (navigateur, appli, etc.)
4. Ã€ chaque requÃªte, le token est envoyÃ© dans lâ€™entÃªte HTTP :

    ```
     Authorization: Bearer eyJhbGciOi...
    ```
5. Le serveur (API ou service) vÃ©rifie la signature et les permissions dans le token.

### â¤ Avantages :

- Sans Ã©tat (stateless) : tout est dans le token
- Facile Ã  intÃ©grer avec des middlewares ou des API Gateway
- SÃ©curitÃ© renforcÃ©e via HTTPS + expiration automatique

| Ã‰lÃ©ment      | RÃ´le principal                                   |
| ------------ | ------------------------------------------------ |
| **Keycloak** | Authentifie les utilisateurs, dÃ©livre des tokens |
| **OAuth2**   | Protocole dâ€™autorisation                         |
| **JWT**      | Format de token sÃ©curisÃ© et vÃ©rifiable           |

# IV. API et rÃ©seaux
![[Pasted image 20250423160953.png]]
## 1. Architecture dâ€™une API REST

L'architecture d'une **APIÂ REST**Â (REpresentational State Transfer)Â est basÃ©e sur un ensemble de contraintes qui visent Ã  crÃ©er des services web ou des applications. Ces contraintes incluent une architecture client-serveur, une communication sans Ã©tat, la possibilitÃ© de stocker des donnÃ©es en cache, une interface uniforme entre les composants et des messages auto-dÃ©scriptifs.24

Une **API REST** doit respecter ces critÃ¨res pour Ãªtre considÃ©rÃ©e comme **RESTful** : elle doit avoirÂ une architecture client-serveur composÃ©e de clients, de serveurs et de ressources, avec des requÃªtes gÃ©rÃ©es par HTTP. La communication client-serveur doit Ãªtre sans Ã©tat, ce qui signifie que les informations du client ne sont pas stockÃ©es entre les requÃªtes GET et que chaque requÃªte est indÃ©pendante et non connectÃ©e.4

L'interface uniforme entre les composants est essentielle car elle permet la communication entre le client et le serveur dans un langage unique, indÃ©pendamment de l'architecture backend. Cela inclut l'utilisation d'HTTP avec des ressources URI, **CRUD (Create, Read, Update, Delete)** et JSON.6

Les contraintes REST permettent de crÃ©er une API qui n'est pas dictÃ©e par son architecture, mais par les reprÃ©sentations qu'elle retourne. Bien que l'API soit architecturalement sans Ã©tat, elle dÃ©pend des reprÃ©sentations pour dÃ©finir l'Ã©tat de l'application.6

Une API REST peut Ãªtre utilisÃ©e pour dÃ©velopper des services web ou pour se connecter Ã  des applications cloud. Par exemple, l'API Graph de Facebook est un bon exemple d'API REST, permettant aux logiciels de communiquer avec l'application Facebook pour publier des messages, recueillir des donnÃ©es et gÃ©rer des annonces.5

Les API REST sont les plus utilisÃ©es dans les architectures distribuÃ©es ou basÃ©es sur des services, car elles sont indÃ©pendantes du type de plateforme ou des langages utilisÃ©s entre le client et le serveur.5

Les contraintes REST incluent Ã©galement la possibilitÃ© de stocker des donnÃ©es en cache pour rÃ©duire le nombre d'interactions avec l'API, rÃ©duire l'utilisation interne du serveur et fournir aux utilisateurs de l'API les outils nÃ©cessaires pour fournir les applications les plus rapides et les plus efficaces possibles.
#### **Principes clÃ©s**Â :

- **Client-Serveur**Â : SÃ©paration claire entre le client (frontend) et le serveur (backend).
- **Sans Ã©tat (Stateless)**Â : Chaque requÃªte contient toutes les informations nÃ©cessaires (ex : token dâ€™authentification).
- **Ressources**Â : Les donnÃ©es sont exposÃ©es comme desÂ **ressources**Â identifiÃ©es par des URLs (ex :Â `/users`,Â `/products`).
- **Verbes HTTP**Â : Utilisation des mÃ©thodes HTTP pour les opÃ©rations :
    
    - `GET`Â : Lire une ressource.
    - `POST`Â : CrÃ©er une ressource.
    - `PUT`/`PATCH`Â : Mettre Ã  jour.
    - `DELETE`Â : Supprimer.
        
- **ReprÃ©sentations**Â : Les rÃ©ponses sont souvent en JSON ou XML.
    
```
GET /users â†’ liste tous les utilisateurs
POST /users â†’ ajoute un nouvel utilisateur
GET /users/1 â†’ affiche lâ€™utilisateur avec lâ€™ID 1
PUT /users/1 â†’ modifie lâ€™utilisateur 1
DELETE /users/1 â†’ supprime lâ€™utilisateur 1
```
#### **Exemple dâ€™endpoint REST**Â :


## 2. ModÃ¨le CRUD (Create, Read, Update, Delete)

### ğŸ“Œ DÃ©finition :

CRUD est un acronyme qui dÃ©crit les **4 opÃ©rations de base** pour manipuler des donnÃ©es.

| OpÃ©ration  | MÃ©thode HTTP     | Action              | Exemple URL   |
| ---------- | ---------------- | ------------------- | ------------- |
| **Create** | `POST`           | CrÃ©er une ressource | `/articles`   |
| **Read**   | `GET`            | Lire une ressource  | `/articles/1` |
| **Update** | `PUT` ou `PATCH` | Mettre Ã  jour       | `/articles/1` |
| **Delete** | `DELETE`         | Supprimer           | `/articles/1` |
#### Demandes de **GET**

Une requÃªte **GET** rÃ©cupÃ¨re une reprÃ©sentation de la ressource au niveau de lâ€™URI spÃ©cifiÃ©. Le corps du message de rÃ©ponse contient les dÃ©tails de la ressource demandÃ©e.

Une requÃªte **GET** doit retourner lâ€™un des codes dâ€™Ã©tat HTTP suivants :

| Code dâ€™Ã©tat HTTP     | Motif                                                                                                                                                 |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| 200 (OK)             | La mÃ©thode a retournÃ© la ressource avec succÃ¨s.                                                                                                       |
| 204 (Pas de contenu) | Le corps de la rÃ©ponse ne contient aucun contenu, par exemple lorsquâ€™une requÃªte de recherche ne retourne aucune correspondance dans la rÃ©ponse HTTP. |
| 404 (Introuvable)    | La ressource demandÃ©e est introuvable.                                                                                                                |
#### Demandes de **POST**

Une requÃªte **POST** doit crÃ©er une ressource. Le serveur affecte un URI pour la nouvelle ressource et retourne cet URI au client.

Importante

Pour les requÃªtes **POST**, un client ne doit pas tenter de crÃ©er son propre URI. Le client doit soumettre la demande Ã  lâ€™URI de la collection, et le serveur doit affecter un URI Ã  la nouvelle ressource. Si un client tente cette opÃ©ration et Ã©met une requÃªte **POST** vers un URI spÃ©cifique, le serveur retourne le code dâ€™Ã©tat HTTP 400 (DEMANDE INCORRECTE) pour indiquer que la mÃ©thode nâ€™est pas prise en charge.

Dans un modÃ¨le RESTful, les requÃªtes **POST** sont gÃ©nÃ©ralement utilisÃ©es pour ajouter une nouvelle ressource Ã  la collection identifiÃ©e par lâ€™URI. Toutefois, une demande **POST** peut Ã©galement Ãªtre utilisÃ©e pour envoyer des donnÃ©es Ã  des fins de traitement Ã  une ressource existante, sans aucune nouvelle ressource crÃ©Ã©e.

Une requÃªte **POST** doit retourner lâ€™un des codes dâ€™Ã©tat HTTP suivants :

|Code dâ€™Ã©tat HTTP|Motif|
|---|---|
|200 (OK)|La mÃ©thode a effectuÃ© un traitement, mais ne crÃ©e pas de ressource. Le rÃ©sultat de lâ€™opÃ©ration peut Ãªtre inclus dans le corps de la rÃ©ponse.|
|201 (crÃ©Ã©)|La ressource a Ã©tÃ© crÃ©Ã©e avec succÃ¨s. Lâ€™URI de la nouvelle ressource est inclus dans lâ€™en-tÃªte Location de la rÃ©ponse. Le corps de la rÃ©ponse contient une reprÃ©sentation de la ressource.|
|204 (Pas de contenu)|Le corps de la rÃ©ponse ne contient aucun contenu.|
|400 (RequÃªte incorrecte)|Le client a placÃ© des donnÃ©es non valides dans la requÃªte. Le corps de la rÃ©ponse peut contenir plus dâ€™informations sur lâ€™erreur ou un lien vers un URI qui fournit plus de dÃ©tails.|
|405 (MÃ©thode non autorisÃ©e)|Le client a tentÃ© dâ€™envoyer une requÃªte POST Ã  un URI qui ne prend pas en charge ces demandes.|

#### RequÃªte de **PUT**

Une demande **PUT** doit mettre Ã  jour une ressource existante sâ€™il existe ou, dans certains cas, crÃ©er une ressource si elle nâ€™existe pas. Le processus dâ€™Ã©tablissement dâ€™une demande **PUT** est le suivant :

1. Le client spÃ©cifie lâ€™URI de la ressource et inclut le corps de la demande qui contient une reprÃ©sentation complÃ¨te de la ressource.
2. Le client effectue la requÃªte.
3. Si une ressource avec cet URI existe dÃ©jÃ , elle est remplacÃ©e. Sinon, une nouvelle ressource est crÃ©Ã©e si lâ€™itinÃ©raire prend en charge cette opÃ©ration.

Les mÃ©thodes **PUT** sont gÃ©nÃ©ralement appliquÃ©es aux ressources qui sont des Ã©lÃ©ments individuels, tels quâ€™un client spÃ©cifique, plutÃ´t que des collections. Un serveur peut prendre en charge les mises Ã  jour, mais pas la crÃ©ation via **PUT**. La prise en charge de la crÃ©ation via **PUT** dÃ©pend du fait que le client peut affecter de maniÃ¨re significative et fiable un URI Ã  une ressource avant que celle-ci n'existe. Si ce nâ€™est pas le cas, utilisez **POST** pour crÃ©er des ressources et demandez au serveur dâ€™affecter lâ€™URI, puis utilisez **PUT** ou **PATCH** pour mettre Ã  jour.

Importante

Les requÃªtes PUT doivent Ãªtre idempotentes. Si un client envoie la mÃªme requÃªte **PUT** plusieurs fois, les rÃ©sultats doivent toujours Ãªtre identiques (la mÃªme ressource sera modifiÃ©e avec les mÃªmes valeurs). Les requÃªtes **POST** et **PATCH** ne sont pas garanties dâ€™Ãªtre idempotentes.

Une requÃªte **PUT** doit retourner lâ€™un des codes dâ€™Ã©tat HTTP suivants :

|Code dâ€™Ã©tat HTTP|Motif|
|---|---|
|200 (OK)|La ressource a Ã©tÃ© mise Ã  jour avec succÃ¨s.|
|201 (crÃ©Ã©)|La ressource a Ã©tÃ© crÃ©Ã©e avec succÃ¨s. Le corps de la rÃ©ponse peut contenir une reprÃ©sentation de la ressource.|
|204 (Pas de contenu)|La ressource a Ã©tÃ© mise Ã  jour avec succÃ¨s, mais le corps de la rÃ©ponse ne contient aucun contenu.|
|409 (Conflit)|Impossible de terminer la requÃªte en raison dâ€™un conflit avec lâ€™Ã©tat actuel de la ressource.|

Conseil / Astuce

Envisagez dâ€™implÃ©menter des opÃ©rations HTTP PUT en bloc qui peuvent effectuer des mises Ã  jour par lots vers plusieurs ressources dâ€™une collection. La requÃªte PUT doit spÃ©cifier lâ€™URI de la collection, et le corps de la demande doit spÃ©cifier les dÃ©tails des ressources Ã  modifier. Cette approche peut aider Ã  rÃ©duire les chattines et Ã  amÃ©liorer les performances.

#### requÃªtes **PATCH**

Une requÃªte PATCH effectue uneÂ _mise Ã  jour partielle_Â vers une ressource existante. Le client spÃ©cifie lâ€™URI de la ressource. Le corps de la demande spÃ©cifie un ensemble deÂ _modifications_Â Ã  appliquer Ã  la ressource. Cela peut Ãªtre plus efficace que lâ€™utilisation de PUT, car le client envoie uniquement les modifications, et non la reprÃ©sentation entiÃ¨re de la ressource. Techniquement, PATCH peut Ã©galement crÃ©er une ressource (en spÃ©cifiant un ensemble de mises Ã  jour vers une ressource Â« null Â»), si le serveur prend en charge cette opÃ©ration.

Avec une requÃªte PATCH, le client envoie un ensemble de mises Ã  jour Ã  une ressource existante, sous la forme dâ€™unÂ _document patch_. Le serveur traite le document de correctif pour effectuer la mise Ã  jour. Le document patch ne dÃ©crit pas lâ€™ensemble de la ressource, seul un ensemble de modifications Ã  appliquer. La spÃ©cification de la mÃ©thode PATCH ([RFC 5789](https://tools.ietf.org/html/rfc5789)) ne dÃ©finit pas un format particulier pour les documents patch. Le format doit Ãªtre dÃ©duit du type de mÃ©dia dans la requÃªte.

JSON est probablement le format de donnÃ©es le plus courant pour les API web. Il existe deux formats de correctifs JSON principaux, appelÃ©sÂ _correctifs JSON_Â etÂ _correctif de fusion JSON_.

Le correctif de fusion JSON est un peu plus simple. Le document patch a la mÃªme structure que la ressource JSON dâ€™origine, mais inclut uniquement le sous-ensemble de champs qui doivent Ãªtre modifiÃ©s ou ajoutÃ©s. En outre, un champ peut Ãªtre supprimÃ© en spÃ©cifiantÂ `null`Â la valeur du champ dans le document patch. (Cela signifie que le correctif de fusion ne convient pas si la ressource dâ€™origine peut avoir des valeurs null explicites.)

Par exemple, supposons que la ressource dâ€™origine a la reprÃ©sentation JSON suivante :

```
{ 
  "name":"gizmo", 
  "category":"widgets", 
  "color":"blue", 
  "price":10 
}
```

Voici un correctif de fusion JSON possible pour cette ressource :

```
{
    "price":12,
    "color":null,
    "size":"small"
}
```
Cela indique au serveur de mettre Ã  jourÂ `price`, supprimerÂ `color`et ajouterÂ `size`, pendantÂ `name`Â etÂ `category`Â ne sont pas modifiÃ©s. Pour obtenir les dÃ©tails exacts du correctif de fusion JSON, consultezÂ [RFC 7396](https://tools.ietf.org/html/rfc7396). Le type de mÃ©dia pour le correctif de fusion JSON estÂ `application/merge-patch+json`.

Le patch de fusion ne convient pas si la ressource d'origine peut contenir des valeurs nulles explicites, en raison de la signification spÃ©ciale duÂ `null`Â dans le document patch. En outre, le document de correctif ne spÃ©cifie pas lâ€™ordre dans lequel le serveur doit appliquer les mises Ã  jour, ce qui peut ne pas Ãªtre important, en fonction des donnÃ©es et du domaine. Le correctif JSON, dÃ©fini dansÂ [RFC 6902](https://tools.ietf.org/html/rfc6902), est plus flexible, car il spÃ©cifie les modifications en tant que sÃ©quence dâ€™opÃ©rations Ã  appliquer. Les opÃ©rations incluent lâ€™ajout, la suppression, le remplacement, la copie et le test (pour valider les valeurs). Le type de mÃ©dia pour le correctif JSON estÂ `application/json-patch+json`.

Une requÃªte PATCH doit retourner lâ€™un des codes dâ€™Ã©tat HTTP suivants :

|Code dâ€™Ã©tat HTTP|Motif|
|---|---|
|200 (OK)|La ressource a Ã©tÃ© mise Ã  jour avec succÃ¨s.|
|400 (RequÃªte incorrecte)|Document de correctif incorrect.|
|409 (Conflit)|Le document patch est valide, mais les modifications ne peuvent pas Ãªtre appliquÃ©es Ã  la ressource dans son Ã©tat actuel.|
|415 (type de mÃ©dia non pris en charge)|Le format de document de correctif nâ€™est pas pris en charge.|

#### Demandes de suppression

Une demande DELETE supprime la ressource Ã  lâ€™URI spÃ©cifiÃ©.

Une requÃªte DELETE doit retourner lâ€™un des codes dâ€™Ã©tat HTTP suivants :

|Code dâ€™Ã©tat HTTP|Motif|
|---|---|
|204 (AUCUN CONTENU)|La ressource a Ã©tÃ© supprimÃ©e avec succÃ¨s. Le processus a Ã©tÃ© gÃ©rÃ© avec succÃ¨s et le corps de la rÃ©ponse ne contient aucune information supplÃ©mentaire.|
|404 (INTROUVABLE)|La ressource nâ€™existe pas.|

source:https://learn.microsoft.com/fr-fr/azure/architecture/best-practices/api-design
## 3. Fonctionnement dâ€™un Reverse Proxy (ex : NGINX)

### ğŸ“Œ DÃ©finition :

Un **reverse proxy** est un **intermÃ©diaire entre les clients et les serveurs**. Contrairement Ã  un **proxy classique (forward proxy)** qui cache les utilisateurs, un **reverse proxy cache les serveurs**.

ğŸ‘‰ Il reÃ§oit les requÃªtes des clients et les redirige vers le bon service interne (ex : une API, un site web, un conteneur Docker).
![[1_DhHPPuJov8kN2mjiX0WCMw.webp]]

*selon Medium*
> Un proxy inverse (reverse proxy) est un type de serveur, habituellement placÃ© en frontal de serveurs web. Contrairement au serveur proxy qui permet Ã  un utilisateur dâ€™accÃ©der au rÃ©seau Internet, le proxy inverse permet Ã  un utilisateur dâ€™Internet dâ€™accÃ©der Ã  des serveurs internes. Une des applications courantes du proxy inverse est la rÃ©partition de charge (load-balancing).
### ğŸ”§ Il sert Ã  :

- **Rediriger les requÃªtes** vers le bon service (load balancing)
    
- **Cacher certaines ressources** pour les charger plus vite (cache)
    
- **SÃ©curiser les accÃ¨s** (SSL, firewall, authentification)
    
- **Masquer lâ€™architecture interne** au client

## ğŸ” Pourquoi utiliser un reverse proxy ?

Voici les **fonctions clÃ©s** :

|Fonction|Description|
|---|---|
|ğŸ¯ **Routage intelligent**|Dirige les requÃªtes selon le chemin, le domaine ou lâ€™URL|
|ğŸ“¦ **RÃ©partition de charge**|Distribue les requÃªtes vers plusieurs serveurs (load balancing)|
|ğŸ” **SSL/HTTPS**|GÃ¨re les certificats SSL pour sÃ©curiser le trafic|
|ğŸšª **AccÃ¨s restreint**|Bloque ou filtre les connexions (firewall applicatif)|
|ğŸš€ **Cache**|Stocke des rÃ©ponses pour accÃ©lÃ©rer les rÃ©ponses (reverse caching)|
|ğŸ› ï¸ **Simplifie la config**|Un seul point dâ€™entrÃ©e, mÃªme si tu as 10 apps derriÃ¨re|
## ğŸ§  Fonctionnement schÃ©matique

```
    Navigateur client (Internet)
                |
                â†“
      ğŸ” NGINX Reverse Proxy (443/80)
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚     Routage, SSL, cache    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           |           |         |
      â†™ï¸        â†˜ï¸       â†˜ï¸
 App 1     API REST     Interface Admin
(3000)     (4000)         (5000)

```



---
### ğŸ“Š Exemple simple avec NGINX :

Imagine un utilisateur qui tape `www.toncloud.com`. Voici ce que fait NGINX :
```
Navigateur â†’ NGINX (port 443)
                   â†“
        Redirige vers ton app (port 3000)
```

```
server {
    listen 443 ssl;
    server_name moncloud.local;

    location / {
        proxy_pass http://localhost:3000;
    }
}

```
*source:(https://search.brave.com/search?q=Architecture+d%E2%80%99une+API+REST&source=desktop&conversation=1b9db0d6df3a79089fef2a&summary=1)*

Un reverse proxy NGINX transmet les requÃªtes des clients aux serveurs et vice-versa. Il agit comme un pont entre les appareils clients et les serveurs dorsaux, tels que LiteSpeed ou Apache, en gÃ©rant les requÃªtes entrantes dans une configuration de proxy inverse. Lorsquâ€™un appareil client envoie des requÃªtes HTTP Ã  votre application web, ces requÃªtes atteignent dâ€™abord le serveur reverse proxy NGINX, qui examine ensuite les dÃ©tails de la requÃªte, tels que lâ€™URL et les en-tÃªtes, afin de dÃ©terminer le traitement appropriÃ©.23

Pour configurer NGINX en tant que reverse proxy, vous devez crÃ©er un nouveau fichier de configuration. Ce fichier contiendra les blocs du serveur et les directives nÃ©cessaires au routage des requÃªtes. Voici un exemple de configuration de base :

```
server {
    listen 80;
    server_name example.com;
    location / {
        proxy_pass http://your_backend_server_ip;
        proxy_set_header Host $host; # Forwarded host
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_redirect off;
    }
}
```

Dans cet exemple, remplacezÂ `your_backend_server_ip`Â par lâ€™adresse IP rÃ©elle de votre serveur back-end.2

Pour mettre en place un Ã©quilibreur de charge, dÃ©finissez un blocÂ `upstream`Â et utilisezÂ `proxy_pass`Â dans votre blocÂ `serveur`Â pour rÃ©partir le trafic entre plusieurs serveurs.

Les avantages d'utiliser NGINX comme reverse proxy incluent la rÃ©duction de la charge sur les serveurs d'applications, la navigation Ã  travers les pare-feu qui protÃ¨gent les ressources en arriÃ¨re-plan, la possibilitÃ© de servir du contenu statique pour rÃ©duire la charge sur les serveurs d'applications, et la simplification de la gestion de l'accÃ¨s utilisateur avec un point d'accÃ¨s unique Ã  votre site.

source:(https://search.brave.com/search?q=3.+Fonctionnement+d%E2%80%99un+Reverse+Proxy+%28ex+%3A+NGINX%29&source=desktop&conversation=00a54a3b7afe2b909b8ad2&summary=1)

# V. Gestion de code source avec Git

## 1. Principes de Git : dÃ©pÃ´t, commit, push, pull, merge

## 2. GitFlow Workflow : organisation des branches

# VI. Stockage et fonctions serverless

## 1. Quâ€™est-ce que MinIO : stockage dâ€™objets compatible S3

## 2. Introduction Ã  OpenFaaS et Knative : fonctions serverless sur Kubernetes

# VII. Supervision et journalisation

## 1. Centralisation des logs avec Grafana et Loki

## 2. Collecte et visualisation des logs applicatifs

# VIII. SystÃ¨me dâ€™exploitation pour les serveurs

## 1. Comparaison : Ubuntu Server, CentOS, Debian, Rocky Linux, etc.


### ğŸ† Classement des distributions Linux pour serveurs

| Rang | Distribution                        | Points forts                                                                                                                                                                                                    | Cas d'utilisation typique                                                                                |
| ---- | ----------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£  | **Ubuntu Server (LTS)**             | - TrÃ¨s populaire et largement utilisÃ©e- FacilitÃ© d'installation et d'utilisation- IntÃ©gration fluide avec les plateformes cloud comme AWS et Azure- Support LTS de 5 ans, idÃ©al pour les environnements stables | Cloud privÃ©/public, DevOps, hÃ©bergement web, conteneurs, serveurs d'applications                         |
| 2ï¸âƒ£  | **Debian**                          | - RÃ©putÃ©e pour sa stabilitÃ© et sa robustesse- Gestion efficace des paquets avec APT- Base de nombreuses autres distributions- Documentation complÃ¨te                                                            | Serveurs critiques, infrastructures cloud, conteneurs, environnements nÃ©cessitant une grande stabilitÃ©   |
| 3ï¸âƒ£  | **Red Hat Enterprise Linux (RHEL)** | - Support professionnel avec mises Ã  jour rÃ©guliÃ¨res- SÃ©curitÃ© renforcÃ©e et conformitÃ© aux normes- IntÃ©gration avec diverses solutions logicielles- Support Ã©tendu de 10 ans sur le systÃ¨me de base             | Entreprises, data centers, cloud hybride, environnements nÃ©cessitant un support professionnel            |
| 4ï¸âƒ£  | **AlmaLinux**                       | - Successeur communautaire de CentOS- 100% compatible avec RHEL- Support jusqu'en 2029- Soutenu par des institutions comme le CERN et le Fermilab                                                               | Environnements d'entreprise, cloud, hÃ©bergeurs, utilisateurs recherchant une alternative gratuite Ã  RHEL |
| 5ï¸âƒ£  | **Rocky Linux**                     | - Alternative communautaire Ã  CentOS- CompatibilitÃ© totale avec RHEL- Cycle de vie de support de 10 ans- DÃ©veloppement intensif par la communautÃ©                                                               | Entreprises, calcul haute performance (HPC), environnements critiques nÃ©cessitant stabilitÃ© et support   |
| 6ï¸âƒ£  | **CentOS Stream**                   | - Version rolling release de RHEL- ReÃ§oit les mises Ã  jour avant RHEL- Bon pour les tests et le dÃ©veloppement                                                                                                   | DÃ©veloppement, prÃ©-production, environnements nÃ©cessitant des mises Ã  jour frÃ©quentes                    |
